{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikoshaa/2141720007-machine-learning-2023/blob/main/Week-10/Tugas_JS_10_Recurrent_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wildan Hafidz Mauludin**\n",
        "\n",
        "**2141720007**"
      ],
      "metadata": {
        "id": "_7ut4w8v5Qoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tugas**\n",
        "\n",
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.\n",
        "\n",
        "Gunakan  untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca.\n",
        "\n",
        "Prosedurnya adalah:\n",
        "\n",
        "- Jalankan Model dan hitung loss dengan .\n",
        "- Hitung update dan terapkan pada model dengan optimizer"
      ],
      "metadata": {
        "id": "HiucjykF5WW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jawab**"
      ],
      "metadata": {
        "id": "EH_UnlFG5Yz1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX6Da_af_dXH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "scpyKsXKF3Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kbO2r92Fghl",
        "outputId": "56e18aa1-46d8-477a-84f3-e680ecc7f5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "umyN24HxGInM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHQV9tARF5R7",
        "outputId": "29aa9fea-ace9-4e8b-d837-c711b8cb3d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwOqirVrGOLZ",
        "outputId": "949b9c01-4886-42d6-8e7d-8e4eb1c729bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRvzXYJ4GVsq",
        "outputId": "937f1460-ceab-4d6f-94f2-b91e53760ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique characters\n",
        "for char in vocab:\n",
        "    print(char, end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1q7QMnHIKMa",
        "outputId": "05256e16-0a05-4083-e29d-86c9c02c380a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Olah Teks"
      ],
      "metadata": {
        "id": "1e8AseEWH0Xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize Teks"
      ],
      "metadata": {
        "id": "uU8l4znrJCmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "OIu9pjuMJFuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iheB-8ZGIQkm",
        "outputId": "5ece846b-b488-4b5d-b0b9-4e4268baa93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "5TcFZnC0LJsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "s6OG1PcSJYQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "Jx62JPLJLYfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "963Z3L-dLU-o",
        "outputId": "79c5e047-3720-4075-f479-9d90e41ea67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode"
      ],
      "metadata": {
        "id": "chxnvVTlYUwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "B0sObC6uLc5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ],
      "metadata": {
        "id": "qabuA_SPYcLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RIpTdvoXw_m",
        "outputId": "52ed943b-22ad-4bbd-f543-d362c81ceb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoXzdaZZYX-1",
        "outputId": "66997bbb-2373-42b5-f777-d4a28f05cc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "OtF7JhJmYn7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi"
      ],
      "metadata": {
        "id": "RLFJUPcsZEmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Training Set dan Target"
      ],
      "metadata": {
        "id": "YSB6IBYCZHjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bHEqISCZBlt",
        "outputId": "84d286d3-ca6b-4fb4-9172-faf5d7809ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "QIMXGoXsZQNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0i6FtI1ZUJ2",
        "outputId": "3eabc547-3656-4ff0-d30a-8844c452c316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "kGbc6MVGZrEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "f0LOUSzJabl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIVqQTEYaELm",
        "outputId": "8281a32a-8140-49fe-cc39-96b4f22a8eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "VY78qrFaa3Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wslsP-OAaful",
        "outputId": "2b892f19-dd6d-42c9-8a57-43aba7481f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "7MfYqUMBbL2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "opzxqqSXa-Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6H-t9Mebk_B",
        "outputId": "6396c0b0-7ab7-4e7f-e903-b48b44f2d96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "fmsj-cYybnkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBAvhx1sb2KJ",
        "outputId": "55230aef-9d86-4fc5-9f93-5284c205626f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Batch Training\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "yjBuEPntcTTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smwEj831cAMz",
        "outputId": "ea0d1c48-773c-492a-8698-63084d4851c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Model"
      ],
      "metadata": {
        "id": "1UFdjpdvcro0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "nWb5toxMccsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "CIRhoWLpc4_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "Fui7NL-Lc6-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Model"
      ],
      "metadata": {
        "id": "qPVl5yQ6dASL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnWrLjBc9WA",
        "outputId": "32b49031-ba2d-454c-d249-5e36000fc881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpK0HsXydfxx",
        "outputId": "937bb025-6812-43a8-8cae-b70ed5796459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "c9572vG0dSaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wmcvoqZdVY3",
        "outputId": "6f1cb2f9-dbf4-4f56-b3cd-7da6c647022d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 19, 41, 13, 43, 38, 61, 50, 53,  7, 49, 25, 30, 14,  5, 29, 16,\n",
              "        7, 33, 40, 33,  9, 64, 52, 28,  9, 37, 11, 64,  9, 59, 10, 65, 62,\n",
              "       61, 34, 28,  7, 65, 21, 24,  7, 16, 42, 61, 20, 58, 36, 14, 46, 25,\n",
              "       29,  6, 13, 34, 36, 30,  3, 35, 47, 33, 32, 64, 33, 51, 47, 43,  1,\n",
              "       34, 43, 27,  5, 60, 45, 37, 17, 51, 45, 58, 65,  6, 55, 34, 31, 17,\n",
              "       25, 44, 41, 54, 50, 37, 23, 57, 63, 14, 54, 20, 22, 11, 44])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "iQVn09PjeQmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUD6JykleCQ2",
        "outputId": "2410f1bc-4383-4576-8fc3-452762ea18f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'was no more behind\\nBut such a day to-morrow as to-day,\\nAnd to be boy eternal.\\n\\nHERMIONE:\\nWas not my '\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"$Fb?dYvkn,jLQA&PC,TaT.ymO.X:y.t3zwvUO,zHK,CcvGsWAgLP'?UWQ!VhTSyTlhd\\nUdN&ufXDlfsz'pURDLebokXJrxAoGI:e\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model\n",
        "\n",
        "Tambahan optimizer dan fungsi loss\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ],
      "metadata": {
        "id": "3P8r6gD0eeAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "DDEEYiQIeS5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IaGO175hRWD",
        "outputId": "0db99dd8-ca4a-4936-f2cd-d7af7fdc8da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1896234, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "dky5dzO1hmLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWtoUmMyhX-y",
        "outputId": "2fc3aacb-98b1-40ed-8888-736ba17cd58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.99793"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "SotmR9pJhpuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "9WPI70RuhiNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoints\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "N7E89t4Zhvju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "23AY9Ob2hsi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan Proses Training"
      ],
      "metadata": {
        "id": "o4Xb0R-Ch4mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "aXC_QdPEh2R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E3BsQpxh9F2",
        "outputId": "aec380a7-7067-47ff-a0e4-85754c405c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 16s 52ms/step - loss: 2.7345\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.9926\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.7133\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.5498\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.4514\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 1.3829\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.3305\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2847\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 1.2437\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 13s 54ms/step - loss: 1.2036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Teks\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ],
      "metadata": {
        "id": "CV0hF8Q4iGJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "xSpe_M7CiBQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "fseLrMJeic8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLaFPvcFifh_",
        "outputId": "ad726c06-0000-445a-a025-28b9a8770597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Come on, and I am, courage-tongue?\n",
            "And now, by revenge, that thereof their son,\n",
            "Fear not them i' the right, wife that you read\n",
            "I show a sister's love, they, 'tis nor money.\n",
            "\n",
            "DORSET:\n",
            "Where was for that For none? we are gloy these all these\n",
            "blood with love and leave you babe,\n",
            "Lest is the easy, a bottle, by their vesimes\n",
            "Would I amms to my grief most keep, help\n",
            "Of bloodness upon the noble and my trot;\n",
            "And you before heaven, do we look'd,\n",
            "There will but revive; I wrink his face\n",
            "themselves; you matching sings and thy books,\n",
            "Impress'd I shall be past, the hopel-seem'd men\n",
            "Than entertain to bow, sing all the corrups\n",
            "Have but every daughter: once modely?\n",
            "\n",
            "BAPTISTA:\n",
            "Would entreat should change you with my father's blood,\n",
            "Thou canst not put on morrower with you shall give you\n",
            "The scare lumbs for by to with wings.\n",
            "\n",
            "GRUMIO:\n",
            "Happile them, with grief, among the rest\n",
            "Grought not on death.\n",
            "\n",
            "LARTIUS:\n",
            "Besides, you mark.\n",
            "\n",
            "LEONTES:\n",
            "I would I cannot cure her,\n",
            "A crownt a maid: a great'st choice\n",
            "Would have  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.8506598472595215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNTARNQ0ilR6",
        "outputId": "71cd82ea-6d4c-46c1-a855-b453c6c1f3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\n\\nWARWICK:\\nYour high both bids him one anornament monawous,\\nBut hangs a forth and virtue.\\nMine it livedy; your solicious parts,\\nIn combiss'd men\\nTo min the dire tine 'palls out and this noble lords\\nAnd yet excuse them all.\\nShup come to be desire in their babes,\\nAnd vow be wited and bosh to any deceited.\\nHence to that earnable, my lord.\\n\\nANIEL:\\nYou gods! we'll ventue yield up for the\\nwedler fancy o'ercass them and my wife's\\nWhose unroled son whose weod, my lord,\\nWith broof and cab; they thrul darland and the queen?\\n\\nThird Gentleman:\\nMy libery sit to have a night and rop\\nOf his lips to die, that he which\\nnature play'd in blood and dishonour in our foe,\\nOur proforrior. Well used none.\\nHave you are called by the windst kakes?\\n\\nSenators, &V:\\nHerry, my lord?\\n\\nPOLIXENES:\\nYou swear to be soleit to be for it?\\n\\nDUKE VINCENTIO:\\nJying by the late, hold, hence; and I will\\ntake hit so his brother, to weep now\\nMost instopation names,\\nTo quit the place Angelo himself;\\nOr why lies all my pity; near'st\\n\"\n",
            " b\"ROMEO:\\nAlack, all not block'd and my death.\\nHere so a thousand men of gonators?\\n\\nGLOUCESTER:\\nThe king now will she belive the babe\\nCommanded my Lord's shane too murder's\\nWincet, and but brow his sub. I\\nboard or Twon, my man must Honour'd quarily\\ntell as heir in the call all, all departune\\nThan thought that his majesty hath put up\\nOnes, full of Romers, indeed, the\\nBrown out their ways, stall I be Cupider' landuigh'd\\nas when is now wine in the health of stat the queen.\\n\\nQUEEN MARGARET:\\nOt for our injirmures Henry to The colour thrife once.\\n\\nCATESBY:\\nI till it forein thine.\\n\\nQUEEN MARGARET:\\nWhat nour'st thou, wall, for our Romeo?\\n\\nKARHINGARET:\\nFirst thou tyman? I am not\\nThe banbay of the home safured,\\nWhich 'tis Norbine but giving him you:\\nFor, by thyself in reverence. I am revenge,\\nThe number's reing wind, thou cannot tell thee,\\nFor we will give you, when he will come\\non the darky room, of back. The battle's joath,\\nFor I bid me fance. Think your hearts, Tybalt, think,\\nAnd I will ade.\\n\\nKING RIC\"\n",
            " b\"ROMEO:\\nSince Norfolk, yield,\\nThe rest was nature to another such.\\nI am too from the mornot then.\\n\\nJOHN Of not, Marcius do?\\nI am content at years till you swear false;\\nWhere weads him rid our lances sent I,--\\nBit my business bids too mock'd for\\nMaistans are none is to begin, be gone and preach\\nhanged, worse may pass you on him honours, nay,\\nOr any hither be affap'd:\\nBetwix thy gates, good queen: seem not be pluck'd\\nFor a bold of sears which of improgubatt\\nHerry that a crookness pake\\nand place-by of the painteous eye, a sorder degree\\nOf souls weeping blame, bestrup and regard\\nThat it fight! Whence are unvented supprues\\nTo talk in sufferance of their wit'st them\\nAs, madam, whether virious to be so.\\nTo behold, up with you?\\n\\nDUKE VINCENTIO:\\nThe heavens grown boy. Take myself\\nLet as my designs and with do't.\\n\\nKATHARINA:\\nNo, sir: my hand went tent; think you to abseem;\\n\\nPERDITA:\\nI pity him to be a bust.\\n\\nPETRUCHIO:\\nWho lost do wast to it?\\n\\nRATCLIFF:\\nWhy, then, I shall not have no subbries--\\nWhich i\"\n",
            " b\"ROMEO:\\nNo woest, if I profess, and I wish you by the quest,\\nWould borrow ready. Go on, vent and creer;\\nThe one take hand Lord's fantish my prepent\\nThereon, too good new mind to Oxford,\\nTo sleep affect the rekelful safress.\\n\\nCAMILLO:\\n\\nKING EDWARD IV:\\nWhy, think, though I at poor man live.\\n\\nSEBASTIAN:\\nWhy, so, too well; whilst I agree?\\n\\nHERMIONE:\\nTrue, the king's blood that be gone?\\n\\nThird Watchman:\\nHere is the world two brother shall be say they; bless it\\nwife, wits curses strike up, grief, suppiarse wild,\\nWhen take the king's of the new-given\\nHis beson thought that no cause to us,\\nI wan to fair Bushop to flat, hath\\nbeen witness into unknown-babber'st as this to think.\\nGive quick an oath fellows on, with whip\\nhim that more, that are with my daughter.\\n\\nGLOUCESTER:\\nSir Parman ready husband, I'll prove not stay.\\n\\nKATHARINA:\\nI prithee, by hope doth have gost; and deward\\nYet thou hast drunk, and hangman.\\n\\nHENRY BOLINGBROKE:\\nHow but show it remained and true sours!\\n\\nELBOW:\\nAy, but he did not still \"\n",
            " b\"ROMEO:\\nIt is a Richard then, and not thy constants\\nAre you will save the nurse, whose enviouls he\\nWill procts thy rearn not\\nTo be contented: though in heavies\\nSpeak stick; I'll kept to wear a ground; and,\\nintitable kings' elseshout amonost out untawning mad,\\nNear ta'en, and there were strongly's life:\\nThoughts I have fought you missolver'd\\nhim to make so supply time to visit\\nFellowning starves of sake: these strike as sleeping by!\\nI'll sleep our current's as easy in fable\\nYour hands. The bindy hat an angry son,\\nGrouggar to the boll, though he be loved\\nTo crave for ever:--vex'd, where are you\\nTalk. Howable title in the king, and blow of hope,\\nCall your son, ay your carele's rogue is free\\nAnd I not safe ye' a bird, I'll undark:\\nYour son, yet I will crown'd in with out the people Richard's blood,\\nTo God and Gevil. What have you good dear fair jack?\\n\\nPETRUCHIO:\\nWell, my must be by my object: A gief\\nwill divines up the inknats have paled alive;\\nAnd now I parted, talk, and bend losalte!\\nWhat then,\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.081352472305298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekspor Model Generator"
      ],
      "metadata": {
        "id": "iWXXp-fijJ2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "id": "0aNHFXrw6eHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sta3e49jjIzD",
        "outputId": "17b3b2da-536a-4093-df3c-5176e23b87b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Did I re gift for babe, he did be long to bed.\n",
            "But mern him to my glory, that\n",
            "stabp'd remembrance o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas\n"
      ],
      "metadata": {
        "id": "li2iKaaMuAMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "2_zqas6vuBno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "bXI36mLUxg5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "GpIUQSAJxobZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uITJPqVxt9c",
        "outputId": "3213aa9e-2822-4780-c0f4-e3456e56259d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 14s 56ms/step - loss: 2.7278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d10c9df2cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print()\n",
        "  print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "  print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmxabmMmxwF6",
        "outputId": "d6d24a23-28e9-40a8-86bc-9616ffeeee9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.2251\n",
            "Epoch 1 Batch 50 Loss 2.0734\n",
            "Epoch 1 Batch 100 Loss 1.9730\n",
            "Epoch 1 Batch 150 Loss 1.8508\n",
            "\n",
            "Epoch 1 Loss: 1.9922\n",
            "Time taken for 1 epoch 12.42 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8328\n",
            "Epoch 2 Batch 50 Loss 1.7246\n",
            "Epoch 2 Batch 100 Loss 1.6894\n",
            "Epoch 2 Batch 150 Loss 1.6207\n",
            "\n",
            "Epoch 2 Loss: 1.7117\n",
            "Time taken for 1 epoch 12.50 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5803\n",
            "Epoch 3 Batch 50 Loss 1.5774\n",
            "Epoch 3 Batch 100 Loss 1.5492\n",
            "Epoch 3 Batch 150 Loss 1.4829\n",
            "\n",
            "Epoch 3 Loss: 1.5494\n",
            "Time taken for 1 epoch 10.99 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4406\n",
            "Epoch 4 Batch 50 Loss 1.4769\n",
            "Epoch 4 Batch 100 Loss 1.4711\n",
            "Epoch 4 Batch 150 Loss 1.4062\n",
            "\n",
            "Epoch 4 Loss: 1.4492\n",
            "Time taken for 1 epoch 11.79 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.4096\n",
            "Epoch 5 Batch 50 Loss 1.3791\n",
            "Epoch 5 Batch 100 Loss 1.3537\n",
            "Epoch 5 Batch 150 Loss 1.3997\n",
            "\n",
            "Epoch 5 Loss: 1.3820\n",
            "Time taken for 1 epoch 11.89 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3269\n",
            "Epoch 6 Batch 50 Loss 1.3049\n",
            "Epoch 6 Batch 100 Loss 1.2911\n",
            "Epoch 6 Batch 150 Loss 1.3686\n",
            "\n",
            "Epoch 6 Loss: 1.3298\n",
            "Time taken for 1 epoch 10.90 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2602\n",
            "Epoch 7 Batch 50 Loss 1.3030\n",
            "Epoch 7 Batch 100 Loss 1.2877\n",
            "Epoch 7 Batch 150 Loss 1.2784\n",
            "\n",
            "Epoch 7 Loss: 1.2855\n",
            "Time taken for 1 epoch 11.06 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.1945\n",
            "Epoch 8 Batch 50 Loss 1.2363\n",
            "Epoch 8 Batch 100 Loss 1.2332\n",
            "Epoch 8 Batch 150 Loss 1.2666\n",
            "\n",
            "Epoch 8 Loss: 1.2442\n",
            "Time taken for 1 epoch 11.79 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1894\n",
            "Epoch 9 Batch 50 Loss 1.1650\n",
            "Epoch 9 Batch 100 Loss 1.2029\n",
            "Epoch 9 Batch 150 Loss 1.2545\n",
            "\n",
            "Epoch 9 Loss: 1.2037\n",
            "Time taken for 1 epoch 12.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.0841\n",
            "Epoch 10 Batch 50 Loss 1.1958\n",
            "Epoch 10 Batch 100 Loss 1.1475\n",
            "Epoch 10 Batch 150 Loss 1.1496\n",
            "\n",
            "Epoch 10 Loss: 1.1636\n",
            "Time taken for 1 epoch 12.43 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Soal**\n",
        "\n",
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ],
      "metadata": {
        "id": "kOh8BW8M3jy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jawab**\n",
        "\n",
        "Perbedaan antara kode tugas dengan praktikum 2 terletak pada prosedur pelatihan.\n",
        "\n",
        "Pada praktikum 2 menggunakan pendekatan pelatihan yang lebih sederhana dan umum digunakan, dengan **model.fit**. Sedangkan kode pada tugas menggambarkan pendekatan pelatihan yang lebih spesifik dan kompleks, yang dilakukan beberapa kustomisasi.\n",
        "\n",
        "Dalam pendekatan ini, mendefinisikan metode train_step dalam model turunan yang mengatur pelatihan pada tingkat batch. Secara eksplisit dilakukan perhitungan loss, gradien, dan menerapkan pembaruan bobot model dengan apply_gradients, serta menggunakan objek tf.metrics.Mean untuk menghitung rata-rata loss selama pelatihan.\n",
        "\n",
        "Pendekatan ini memberikan lebih banyak kontrol dan fleksibilitas dalam pengaturan pelatihan model.\n",
        "\n"
      ],
      "metadata": {
        "id": "AVoaaDIw3pAB"
      }
    }
  ]
}