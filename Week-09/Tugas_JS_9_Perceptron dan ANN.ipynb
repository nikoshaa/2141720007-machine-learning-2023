{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wildan Hafidz Mauludin**\n",
    "\n",
    "**2141720007**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tugas**\n",
    "\n",
    "- Lakukan klasifikasi pada data MNIST dengan menggunakan model ANN\n",
    "- Anda diperbolehkan melakukan eksplorasi terhadap,\n",
    "    - Metode pra pengolahan\n",
    "    - Pemilihan fitur\n",
    "    - Arsitektur ANN\n",
    "    - Fungsi Aktiviasi\n",
    "- ANN diimplementasikan dengan menggunakan tensorflow.\n",
    "- DIKERJAKAN SECARA BERKELOMPOK\n",
    "- JELASKAN HASIL YANG ANDA DAPATKAN,\n",
    "    - AKURASI\n",
    "    - CONFUSION MATRIX\n",
    "    - KONFIGURASI MODEL --> MULAI DARI PRA PENGOLAHAN SAMPAI ARSITEKTUR ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jawab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import Library dan Persiapan Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hubun\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 25s 17ms/step - loss: 0.1859 - accuracy: 0.9443 - val_loss: 0.1029 - val_accuracy: 0.9699\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.0553 - val_accuracy: 0.9821\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0515 - val_accuracy: 0.9834\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0579 - val_accuracy: 0.9825\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9863\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0680 - val_accuracy: 0.9827\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0594 - val_accuracy: 0.9844\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0693 - val_accuracy: 0.9829\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0625 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 23s 17ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0640 - val_accuracy: 0.9843\n",
      "438/438 [==============================] - 3s 5ms/step - loss: 0.0641 - accuracy: 0.9848\n",
      "Akurasi pada data pengujian: 0.98\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unduh dataset MNIST dari scikit-learn\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Pisahkan data gambar dan label\n",
    "images = mnist.data.astype('float32')\n",
    "labels = mnist.target.astype('int')\n",
    "\n",
    "# Langkah 1: Pra-pemrosesan\n",
    "images /= 255.0  # Skalakan data\n",
    "\n",
    "# Bagi data menjadi data pelatihan dan pengujian\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Langkah 2: Definisikan arsitektur model ANN\n",
    "model = models.Sequential([\n",
    "    layers.Reshape(target_shape=(28, 28, 1), input_shape=(784,)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Langkah 3: Kompilasi model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Langkah 4: Latih model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    epochs=10, validation_split=0.2)\n",
    "\n",
    "# Langkah 5: Evaluasi model pada data pengujian\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Akurasi pada data pengujian: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 10s 6ms/step - loss: 0.0185 - accuracy: 0.9950\n",
      "Akurasi pada data pelatihan: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi akurasi data pelatihan\n",
    "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "print(f'Akurasi pada data pelatihan: {train_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 2s 5ms/step\n",
      "Matriks Kebingungan:\n",
      "[[1334    1    2    0    1    1    2    0    1    1]\n",
      " [   0 1584    4    0    1    0    1    3    5    2]\n",
      " [   0    1 1372    1    1    0    1    1    2    1]\n",
      " [   1    1   16 1380    0   18    0    3    7    7]\n",
      " [   0    0    1    0 1275    0    1    1    7   10]\n",
      " [   0    0    1    1    0 1260    3    0    7    1]\n",
      " [   5    0    1    0    1    6 1381    0    2    0]\n",
      " [   1    0   19    1    2    0    0 1475    0    5]\n",
      " [   3    1    4    1    0    3    4    2 1335    4]\n",
      " [   4    0    1    2    9    4    0    4    5 1391]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Membuat prediksi pada data pengujian\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Membuat matriks kebingungan\n",
    "confusion = confusion_matrix(test_labels, predicted_labels)\n",
    "print('Matriks Kebingungan:')\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
